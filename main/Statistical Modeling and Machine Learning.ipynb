{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Modeling and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will cover machine learning with some statistical modeling in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is Machine Learning?\n",
    "Rather than programming expertise into our applications, we program the application to learn from data (predictive analytics) using machine-learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Examples\n",
    "* Improve **weather forecasting** to save lives, minimize injuries and property damage\n",
    "* Improve **cancer diagnoses** and **treatment regimens** to save lives\n",
    "* **Detect fraudulent credit-card purchases** and **insurance claims**\n",
    "* Predict **customer “churn”**, what prices houses are likely to sell for, ticket sales of new movies, and anticipated revenue of new products and services\n",
    "* Predict the **best strategies for coaches and players** to use to win more games and championships\n",
    "* ...and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn \n",
    "* Scikit-learn, also called **sklearn**, conveniently packages the most effective machine-learning algorithms as **estimators**. \n",
    "* **Algorithms are encapsulated, so you don’t see the intricate details and heavy mathematics of how these algorithms work.**\n",
    "* You’ll use **scikit-learn** to **train each model** on a subset of your data, then **test each model** on the rest to see how well your model works. \n",
    "* Once your models are trained, you’ll put them to work making **predictions** based on **data they have not seen**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Scikit-Learn Estimator Should You Choose?\n",
    "* **It’s difficult to know in advance which model(s) will perform best on your data**, so you typically try many models and pick the one that performs best across different types of datasets. \n",
    "* A popular approach is to **run many models and pick the best one(s)** based on scoring\n",
    "* Unless you are super interested and math inclined, **you likely won't know (or need to know) the details of the mathematical algorithms** in the sklearn estimators\n",
    "* With experience, you’ll **become familiar with which algorithms may be best for particular types of datasets and problems**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Datasets Bundled with Scikit-Learn](http://scikit-learn.org/stable/datasets/index.html)\n",
    "* Scikit-learn also provides capabilities for loading datasets from other sources, such as the 20,000+ datasets available at https://openml.org. \n",
    "\n",
    "| Datasets bundled with scikit-learn | &nbsp;\n",
    "| :--- | :---\n",
    "| **_\"Toy\" datasets_** | **_Real-world datasets_**\n",
    "| Boston house prices | Olivetti faces\n",
    "| Iris plants | 20 newsgroups text\n",
    "| Diabetes | Labeled Faces in the Wild face recognition\n",
    "| Optical recognition of handwritten digits | Forest cover types\n",
    "| Linnerrud | RCV1\n",
    "| Wine recognition | Kddcup 99 \n",
    "| Breast cancer Wisconsin (diagnostic) | California Housing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps in Performing Machine Learning \n",
    "* loading the dataset\n",
    "* exploring the data to get a handle on its contents (e.g. numpy, pandas, visualization, etc.)\n",
    "* **Make sure your data is clean before you use it for ML!**\n",
    "* transforming your data (converting non-numeric data to numeric data because scikit-learn requires numeric data\n",
    "* splitting the data for training and testing\n",
    "* creating the model\n",
    "* training and testing the model\n",
    "* tuning the model and evaluating its accuracy\n",
    "* making predictions on live data that the model hasn’t seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series and Simple Linear Regression \n",
    "* **Linear regression** is the **simplest** regression algorithm\n",
    "* Given a collection of numeric values representing an **independent variable** and a **dependent variable**, simple linear regression **describes the relationship between these variables with a straight line**, known as the **regression line**\n",
    "   \\begin{equation}y = m x + b\\end{equation}\n",
    "   * y = mx + b (m is the slope, and b is the value of y when x = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Predicting High Temperatures (NYC Temperature Data)\n",
    "\n",
    "The file `ave_hi_nyc_jan_1895-2018.csv` contains New York City high temperature data for all Januarys from 1895-2018 with the following data:\n",
    "\n",
    "* Date - A value of the form 'YYYYMM'\n",
    "* Value - Tempearture in Fahrenheit\n",
    "* Anomaly - Difference between the value for the given date and average values for all dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data, rename the `'Value'` column to `'Temperature'`, remove `01` from the end of each date value and display a few data samples:\n",
    "df_nyc = pd.read_csv('ave_hi_nyc_jan_1895-2018.csv')\n",
    "df_nyc.columns = ['Date', 'Temperature', 'Anomaly']\n",
    "df_nyc['Date'] = df_nyc['Date'].floordiv(100)\n",
    "df_nyc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data for Training and Testing\n",
    "* We’ll use the **`LinearRegression`** estimator from **`sklearn.linear_model`** \n",
    "* By default, this estimator uses **all** the **numeric features** in a dataset to perform **multiple linear regression**  \n",
    "* For **simple linear regression** select **one** feature (the `Date` here) as the **independent variable**\n",
    "    * Scikit-learn estimators require training and testing data to be **two-dimensional** \n",
    "    * We'll transform **`Series` of _n_** elements, into two dimensions containing **_n_ rows** and **one column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nyc['Temperature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split arrays into train and test subsets which will be randomly selected\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_nyc['Date'].values.reshape(-1, 1), df_nyc['Temperature'].values, random_state=11)  #random_state is for reproducibility to select the same data from training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the **75%–25% train-test split** \n",
    "print(X_train.size, 'items --', X_train.size/(X_train.size + X_test.size) * 100)\n",
    "print(X_test.size, 'items --', X_test.size/(X_train.size + X_test.size) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "* [**LinearRegression default settings**](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "* [**How Do You Know You Have Enough Training Data?**](https://towardsdatascience.com/how-do-you-know-you-have-enough-training-data-ad9b1fd679ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To find the **best fitting regression line** for the data, the `LinearRegression` estimator **iteratively adjusts** the **slope** and **intercept** to **minimize** the **sum of the squares** of the data points’ **distances** from the line.\n",
    "* The slope and intercept are used to make predictions and plot the regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear_regression.coef_) # Slope is the estimator’s **`coeff_`** attribute (**m** in the equation) \n",
    "print(linear_regression.intercept_)  # Intercept is the estimator’s **`intercept_`** attribute (**b** in the equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model\n",
    "* Test the model using the data in **`X_test`** and check some of the **predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = y_test\n",
    "predicted = linear_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p, e in zip(predicted[::5], expected[::5]):  # check every 5th element\n",
    "    print('Predicted: %.2f, Expected: %.2f' % (p, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: What do you think about the predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Future Temperatures and Estimating Past Temperatures \n",
    "* Use the **coefficient** and **intercept** values to make **predictions** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda implements y = mx + b\n",
    "predict = (lambda x: linear_regression.coef_ * x + linear_regression.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The prediction for 1890 is', predict(1890))\n",
    "print('The prediction for 2021 is', predict(2021))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Dataset with the Regression Line \n",
    "* Create a **scatter plot** with a regression line \n",
    "* **Cooler** temperatures shown in **darker colors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes = sns.scatterplot(data=df_nyc, x='Date', y='Temperature', hue='Temperature', palette='winter', legend=False)  \n",
    "axes.set_ylim(10, 70)  # scale y-axis \n",
    "\n",
    "x = np.array([min(df_nyc['Date'].values), max(df_nyc['Date'].values)]) # creates an array from 1895-2018\n",
    "y = predict(x)\n",
    "\n",
    "line = plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting/Underfitting\n",
    "* Common problems that prevent accurate predictions\n",
    "* When creating a model, key goal is **making accurate predictions** for **data it has not yet seen** \n",
    "* **Underfitting** occurs when a **model is too simple to make predictions**, based on its training data\n",
    "    * You attempt to use a linear model when the problem really requires non-linear model\n",
    "* **Overfitting** occurs when your **model is too complex**\n",
    "    * Most extreme case would be a model that memorizes its training data\n",
    "    * Model memorizes the training data and is unable to make predictions with data not yet sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice Problem\n",
    "\n",
    "Using the file, `ave_yearly_temp_nyc_1895-2017.csv`, predict what the average yearly temperature will be in 2030, 2040, and 2050. What are the predictions telling you and what can you infer by this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Multiple Linear Regression (California Housing Dataset)\n",
    "* [**California Housing dataset**](http://lib.stat.cmu.edu/datasets). An example of a data set bundled with scikit-learn, containing 20,640 samples, each with eight numerical features. The dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (typically has a population of 600 to 3,000 people).\n",
    "* The dataset has **20,640 samples**—**one per block group**—with **eight features** each:\n",
    "\t* **median income**—in tens of thousands, so 8.37 would represent $83,700\n",
    "\t* **median house age**—in the dataset, the maximum value for this feature is 52\n",
    "\t* **average number of rooms** \n",
    "\t* **average number of bedrooms** \n",
    "\t* **block population**\n",
    "\t* **average house occupancy**\n",
    "\t* **house block latitude**\n",
    "\t* **house block longitude**\n",
    "    * **Target** &mdash; **median house value** in hundreds of thousands, so 3.55 would represent \\$355,000\n",
    "* Reasonable to expect **more bedrooms**, **more rooms** or **higher income** would mean **higher house value**\n",
    "* **Combine all numeric features to make predictions**\n",
    "    * More likely to get **more accurate predictions** than with simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "california = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm number of **samples/features**, number of **targets**, **feature names**\n",
    "print('Shape', california.data.shape)\n",
    "print('Feature Names', california.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame with a column for median house values\n",
    "california_df = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "california_df['MedHouseValue'] = pd.Series(california.target)\n",
    "california_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some summary statistics\n",
    "california_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Exploration\n",
    "* Helpful to **visualize** data by **plotting the target value** against **each** feature\n",
    "    Shows how **median home value** relates to **each feature**\n",
    "* Use **`DataFrame` method **`sample`**** to **randomly select 10% of the 20,640 samples** for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display scatter plots of several features. Feature on x-axis and median home value on y-axis\n",
    "\n",
    "sample_df = california_df.sample(frac=0.1, random_state=17)\n",
    "sns.set_style('whitegrid')   \n",
    "for feature in california.feature_names:\n",
    "    plt.figure(figsize=(15, 7))  # 15\"-by-7\" Figure\n",
    "    sns.scatterplot(data=sample_df, x=feature, y='MedHouseValue', hue='MedHouseValue', palette='cool', legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: What are the visualizations telling you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![California Housing Dataset scatterplot of Median House Value vs. Median Income](./ch14images/medincome.png \"California Housing Dataset scatterplot of Median House Value vs. Median Income\")\n",
    " ![California Housing Dataset scatterplot of Median House Value vs. House Age](./ch14images/houseage.png \"California Housing Dataset scatterplot of Median House Value vs. House Age\")\n",
    " ![California Housing Dataset scatterplot of Median House Value vs. Average Rooms](./ch14images/averooms.png \"California Housing Dataset scatterplot of Median House Value vs. Average Rooms\")\n",
    " ![California Housing Dataset scatterplot of Median House Value vs. Average Bedrooms](./ch14images/avebedrooms.png \"California Housing Dataset scatterplot of Median House Value vs. Average Bedrooms\")\n",
    " ![California Housing Dataset scatterplot of Median House Value vs. Population](./ch14images/population.png \"California Housing Dataset scatterplot of Median House Value vs. Population\")\n",
    " ![California Housing Dataset scatterplot of Median House Value vs. Average Occupancy](./ch14images/aveoccupancy.png \"California Housing Dataset scatterplot of Median House Value vs. Average Occupancy\")\n",
    " ![California Housing Dataset scatterplot of Median House Value vs. Lattitude](./ch14images/lattitude.png \"California Housing Dataset scatterplot of Median House Value vs. Lattitude\")\n",
    " ![California Housing Dataset scatterplot of Median House Value vs. Longitude](./ch14images/longitude.png \"California Housing Dataset scatterplot of Median House Value vs. Longitude\")<hr style=\"height:2px; border:none; color:black; background-color:black;\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split arrays into train and test subsets which will be randomly selected\n",
    "X_train, X_test, y_train, y_test = train_test_split(california.data, california.target, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the **75%–25% train-test split** \n",
    "print(X_train.size, 'items --', X_train.size/(X_train.size + X_test.size) * 100)\n",
    "print(X_test.size, 'items --', X_test.size/(X_train.size + X_test.size) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model \n",
    "* **`LinearRegression`** tries to use **all** features in a dataset’s `data` array\n",
    "    * **error** if any features are **categorical**  \n",
    "    * Categorical data must be preprocessed into numerical data or excluded\n",
    "* **Scikit-learn’s bundled datasets** are already in the **correct format** for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Separate coefficients** for each feature (stored in `coeff_`) and **one intercept** (stored in `intercept_`) \n",
    "    * **Positive coefficients** &mdash; median house value **increases** as feature value **increases** \n",
    "    * **Negative coefficients** &mdash; median house value **decreases** as feature value **increases**\n",
    "    * **HouseAge**, **AveOccup** and **Population** are **close to zero**, so these apparently have little to no affect on **median house value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slope is the estimator’s **`coeff_`** attribute (**m** in the equation) \n",
    "for i, name in enumerate(california.feature_names): #enumerate adds a number to an iteration\n",
    "    print(f'{name:>10}: {linear_regression.coef_[i]}')  \n",
    "print()    \n",
    "# Intercept is the estimator’s **`intercept_`** attribute (**b** in the equation)\n",
    "print(linear_regression.intercept_)  # Intercept is the estimator’s **`intercept_`** attribute (**b** in the equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can use coefficient values in following equation to **make predictions**:\n",
    "\n",
    "\\begin{equation}\n",
    "y = m_1 x_1 + m_2 x_2 + ... + m_n x_n + b\n",
    "\\end{equation}\n",
    "\n",
    "* <em>m</em><sub>1</sub>, <em>m</em><sub>2</sub>, …, <em>m</em><sub><em>n</em></sub> are the **feature coefficients**\n",
    "* <em>b</em> is the **intercept**\n",
    "* <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub>, …, <em>x</em><sub><em>n</em></sub> are **feature values** (the **independent variables**)\n",
    "* <em>y</em> is the **predicted value** (the **dependent variable**)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = y_test\n",
    "predicted = linear_regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Expected', expected[:5])   # first five targets \n",
    "print('Predicted', predicted[:5])  # first 5 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In **regression**, it’s **tough to get exact predictions**, because you have **continuous outputs**\n",
    "    * Every possible value of <em>x</em><sub>1</sub>, <em>x</em><sub>2</sub> … <em>x</em><sub><em>n</em></sub> in the following calculation predicts a value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Expected vs. Predicted Prices \n",
    "* Create a `DataFrame` containing columns for the expected and predicted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Expected'] = pd.Series(expected)\n",
    "df['Predicted'] = pd.Series(predicted)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the data as a scatter plot with the **expected (target) prices** along the x-axis and the **predicted prices** along the **y**-axis: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(9, 9))\n",
    "axes = sns.scatterplot(data=df, x='Expected', y='Predicted', hue='Predicted', palette='cool', legend=False)\n",
    "\n",
    "start = min(expected.min(), predicted.min())\n",
    "end = max(expected.max(), predicted.max())\n",
    "\n",
    "axes.set_xlim(start, end)\n",
    "axes.set_ylim(start, end)\n",
    "\n",
    "# Note: This is NOT a regression line. It is representing what perfect predictions would look like. If every predicted value matched expected value, all dots would be along dashed line.\n",
    "line = plt.plot([start, end], [start, end], 'k--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: What do you think this model is suggesting regarding expected median house value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Regression Model\n",
    "* **Metrics for regression estimators** include **coefficient of determination** (**$R^{2}$ score**; 0.0-1.0)\n",
    "    * **1.0** &mdash; estimator **perfectly predicts** the **dependent variable’s value**, given independent variables' values\n",
    "    * **0.0** &mdash; **model cannot make predictions with any accuracy**, given independent variables’ values \n",
    "* Calculate with arrays representing the **expected** and **predicted results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.r2_score(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying Other Models\n",
    "* **Try several estimators** to determine whether any **produces better results** than `LinearRegression` \n",
    "* [Information about estimators used here](https://scikit-learn.org/stable/modules/linear_model.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    'LinearRegression': linear_regression,\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the estimators using **k-fold cross-validation** (splits data into folds/splits to handle both training and testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estimator_name, estimator_object in estimators.items():\n",
    "    kfold = KFold(n_splits=10, random_state=11, shuffle=True)\n",
    "    scores = cross_val_score(estimator=estimator_object, X=california.data, y=california.target, cv=kfold, scoring='r2') #cv = cross-validation generator defines how to split the samples; scoring gets R^2 scores for each fold\n",
    "    print(f'{estimator_name:>16}: ' + f'mean of r2 scores={scores.mean():.3f}')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
